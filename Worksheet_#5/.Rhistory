"https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_urv_sm"
)
# Initialize an empty tibble to store all reviews
all_reviews <- tibble()
# Loop through each link and scrape reviews
for (link in links) {
reviews <- rev_scrapes(link)
# Check if reviews are scraped successfully and limit to 20 reviews per link
if (nrow(reviews) > 0) {
reviews <- reviews %>% slice(1:20)  # Limit to the first 20 reviews per link
all_reviews <- bind_rows(all_reviews, reviews)
}
}
library(rvest)
library(dplyr)
library(tibble)
# Define a function to scrape IMDb reviews
rev_scrapes <- function(url) {
# Load the page content
page <- tryCatch(read_html(url), error = function(e) NULL)
if (is.null(page)) {
message("Failed to load page: ", url)
return(tibble())
}
# Extract the title of the show using the correct selector
movie_title <- page %>%
html_nodes("h1[data-testid='hero-title-block__title']") %>%
html_text(trim = TRUE)
# Check if the show title was extracted successfully
if (length(movie_title) == 0) {
message("Failed to extract show title for URL: ", url)
movie_title <- NA  # Set to NA if the title is not found
}
# Extract relevant review data
reviewer_names <- page %>%
html_nodes("a.ipc-link.ipc-link--base") %>%
html_text() %>%
.[. != "Permalink"]
date_review <- page %>%
html_nodes("li.ipc-inline-list__item.review-date") %>%
html_text()
movie_ratings <- page %>%
html_nodes("span.ipc-rating-star--rating") %>%
html_text() %>%
as.numeric()
review_titles <- page %>%
html_nodes("h3.ipc-title__text") %>%
html_text()
helpful_votes <- page %>%
html_nodes("span.ipc-voting__label__count.ipc-voting__label__count--up") %>%
html_text() %>%
as.numeric()
review_texts <- page %>%
html_nodes("div.ipc-html-content-inner-div") %>%
html_text()
# Adjust lengths by padding shorter vectors with NA
max_length <- max(length(reviewer_names), length(date_review), length(movie_ratings), length(review_titles), length(helpful_votes), length(review_texts))
# Pad vectors with NA if they are shorter than max_length
reviewer_names <- c(reviewer_names, rep(NA, max_length - length(reviewer_names)))
date_review <- c(date_review, rep(NA, max_length - length(date_review)))
movie_ratings <- c(movie_ratings, rep(NA, max_length - length(movie_ratings)))
review_titles <- c(review_titles, rep(NA, max_length - length(review_titles)))
helpful_votes <- c(helpful_votes, rep(NA, max_length - length(helpful_votes)))
review_texts <- c(review_texts, rep(NA, max_length - length(review_texts)))
# Combine data into a tibble
tibble(
movie_title = rep(movie_title, max_length),  # Add the show title to each review
reviewer_name = reviewer_names,
review_date = date_review,
rating = movie_ratings,
review_title = review_titles,
helpful_votes = helpful_votes,
review_text = review_texts
)
}
# List of IMDb links
links <- c(
"https://www.imdb.com/title/tt7366338/reviews/?ref_=tt_urv_sm",
"https://www.imdb.com/title/tt0903747/reviews/?ref_=tt_urv_sm",
"https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_urv_sm",
"https://www.imdb.com/title/tt0795176/reviews/?ref_=tt_urv_sm",
"https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_urv_sm"
)
# Initialize an empty tibble to store all reviews
all_reviews <- tibble()
# Loop through each link and scrape reviews
for (link in links) {
reviews <- rev_scrapes(link)
# Check if reviews are scraped successfully and limit to 20 reviews per link
if (nrow(reviews) > 0) {
reviews <- reviews %>% slice(1:20)  # Limit to the first 20 reviews per link
all_reviews <- bind_rows(all_reviews, reviews)
}
}
# View the first 20 reviews after scraping all links
print(all_reviews)
# Optionally, write the reviews to a CSV file
# write.csv(all_reviews, "IMDb_reviews.csv", row.names = FALSE)
# Defining a function in order to scrape IMDb reviews
rev_scrapes <- function(url) {
# Load the page content
page <- tryCatch(read_html(url), error = function(e) NULL)
if (is.null(page)) {
message("Failed to load page: ", url)
return(tibble())
}
# Extract the title of the show using the correct selector
movie_title <- page %>%
html_nodes("h1[data-testid='hero-title-block__title']") %>%
html_text(trim = TRUE)
# Check if the show title was extracted successfully
if (length(movie_title) == 0) {
message("Failed to extract show title for URL: ", url)
movie_title <- NA  # Set to NA if the title is not found
}
# Extract relevant review data
reviewer_names <- page %>%
html_nodes("a.ipc-link.ipc-link--base") %>%
html_text() %>%
.[. != "Permalink"]
date_review <- page %>%
html_nodes("li.ipc-inline-list__item.review-date") %>%
html_text()
movie_ratings <- page %>%
html_nodes("span.ipc-rating-star--rating") %>%
html_text() %>%
as.numeric()
review_titles <- page %>%
html_nodes("h3.ipc-title__text") %>%
html_text()
helpful_votes <- page %>%
html_nodes("span.ipc-voting__label__count.ipc-voting__label__count--up") %>%
html_text() %>%
as.numeric()
review_texts <- page %>%
html_nodes("div.ipc-html-content-inner-div") %>%
html_text()
# Adjust lengths by padding shorter vectors with NA
max_length <- max(length(reviewer_names), length(date_review), length(movie_ratings), length(review_titles), length(helpful_votes), length(review_texts))
# Pad vectors with NA if they are shorter than max_length
reviewer_names <- c(reviewer_names, rep(NA, max_length - length(reviewer_names)))
date_review <- c(date_review, rep(NA, max_length - length(date_review)))
movie_ratings <- c(movie_ratings, rep(NA, max_length - length(movie_ratings)))
review_titles <- c(review_titles, rep(NA, max_length - length(review_titles)))
helpful_votes <- c(helpful_votes, rep(NA, max_length - length(helpful_votes)))
review_texts <- c(review_texts, rep(NA, max_length - length(review_texts)))
# Combine data into a tibble
tibble(
movie_title = rep(movie_title, max_length),  # Add the show title to each review
reviewer_name = reviewer_names,
review_date = date_review,
rating = movie_ratings,
review_title = review_titles,
helpful_votes = helpful_votes,
review_text = review_texts
)
}
# List of IMDb links
links <- c(
"https://www.imdb.com/title/tt0903747/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0795176/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0306414/reviews/?ref_=tt_ov_urv"
)
# Initialize an empty tibble to store all reviews
all_movie_reviews <- tibble()
# Loop through each link and scrape reviews
for (link in links) {
reviews <- rev_scrapes(link)
# Check if reviews are scraped successfully and limit to 20 reviews per link
if (nrow(reviews) > 0) {
reviews <- reviews %>% slice(1:20)  # Limit to the first 20 reviews per link
all_reviews <- bind_rows(all_reviews, reviews)
}
}
# View the first 20 reviews after scraping all links
print(all_reviews)
# Optionally, write the reviews to a CSV file
write.csv(all_movie_reviews, "IMDb_Movie_Reviews.csv", row.names = FALSE)
# Defining a function in order to scrape IMDb reviews
rev_scrapes <- function(url) {
page <- tryCatch(read_html(url), error = function(e) NULL)
if (is.null(page)) {
message("Failed to load page: ", url)
return(tibble())
}
# Extract the title of the show using the correct selector
movie_title <- page %>%
html_nodes("h3.ipc-title__text") %>%
html_text(trim = TRUE)
# Check if the show title was extracted successfully
if (length(movie_title) == 0) {
message("Failed to extract show title for URL: ", url)
movie_title <- NA  # Set to NA if the title is not found
}
# Extract relevant review data
reviewer_names <- page %>%
html_nodes("a.ipc-link.ipc-link--base") %>%
html_text() %>%
.[. != "Permalink"]
date_review <- page %>%
html_nodes("li.ipc-inline-list__item.review-date") %>%
html_text()
movie_ratings <- page %>%
html_nodes("span.ipc-rating-star--rating") %>%
html_text() %>%
as.numeric()
review_titles <- page %>%
html_nodes("h3.ipc-title__text") %>%
html_text()
helpful_votes <- page %>%
html_nodes("span.ipc-voting__label__count.ipc-voting__label__count--up") %>%
html_text() %>%
as.numeric()
review_texts <- page %>%
html_nodes("div.ipc-html-content-inner-div") %>%
html_text()
# Adjust lengths by padding shorter vectors with NA
max_length <- max(length(reviewer_names), length(date_review), length(movie_ratings), length(review_titles), length(helpful_votes), length(review_texts))
# Pad vectors with NA if they are shorter than max_length
reviewer_names <- c(reviewer_names, rep(NA, max_length - length(reviewer_names)))
date_review <- c(date_review, rep(NA, max_length - length(date_review)))
movie_ratings <- c(movie_ratings, rep(NA, max_length - length(movie_ratings)))
review_titles <- c(review_titles, rep(NA, max_length - length(review_titles)))
helpful_votes <- c(helpful_votes, rep(NA, max_length - length(helpful_votes)))
review_texts <- c(review_texts, rep(NA, max_length - length(review_texts)))
# Combine data into a tibble
tibble(
movie_title = rep(movie_title, max_length),  # Add the show title to each review
reviewer_name = reviewer_names,
review_date = date_review,
rating = movie_ratings,
review_title = review_titles,
helpful_votes = helpful_votes,
review_text = review_texts
)
}
# List of IMDb links
links <- c(
"https://www.imdb.com/title/tt0903747/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0795176/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0306414/reviews/?ref_=tt_ov_urv"
)
# Initialize an empty tibble to store all reviews
all_movie_reviews <- tibble()
# Loop through each link and scrape reviews
for (link in links) {
reviews <- rev_scrapes(link)
# Check if reviews are scraped successfully and limit to 20 reviews per link
if (nrow(reviews) > 0) {
reviews <- reviews %>% slice(1:20)  # Limit to the first 20 reviews per link
all_reviews <- bind_rows(all_reviews, reviews)
}
}
# Defining a function in order to scrape IMDb reviews
rev_scrapes <- function(url) {
page <- tryCatch(read_html(url), error = function(e) NULL)
if (is.null(page)) {
message("Failed to load page: ", url)
return(tibble())
}
# Extract the title of the show using the correct selector
movie_title <- page %>%
html_nodes("h1[data-testid='hero-title-block__title']") %>%
html_text(trim = TRUE)
# Check if the show title was extracted successfully
if (length(movie_title) == 0) {
message("Failed to extract show title for URL: ", url)
movie_title <- NA  # Set to NA if the title is not found
}
# Extract relevant review data
reviewer_names <- page %>%
html_nodes("a.ipc-link.ipc-link--base") %>%
html_text() %>%
.[. != "Permalink"]
date_review <- page %>%
html_nodes("li.ipc-inline-list__item.review-date") %>%
html_text()
movie_ratings <- page %>%
html_nodes("span.ipc-rating-star--rating") %>%
html_text() %>%
as.numeric()
review_titles <- page %>%
html_nodes("h3.ipc-title__text") %>%
html_text()
helpful_votes <- page %>%
html_nodes("span.ipc-voting__label__count.ipc-voting__label__count--up") %>%
html_text() %>%
as.numeric()
review_texts <- page %>%
html_nodes("div.ipc-html-content-inner-div") %>%
html_text()
# Adjust lengths by padding shorter vectors with NA
max_length <- max(length(reviewer_names), length(date_review), length(movie_ratings), length(review_titles), length(helpful_votes), length(review_texts))
# Pad vectors with NA if they are shorter than max_length
reviewer_names <- c(reviewer_names, rep(NA, max_length - length(reviewer_names)))
date_review <- c(date_review, rep(NA, max_length - length(date_review)))
movie_ratings <- c(movie_ratings, rep(NA, max_length - length(movie_ratings)))
review_titles <- c(review_titles, rep(NA, max_length - length(review_titles)))
helpful_votes <- c(helpful_votes, rep(NA, max_length - length(helpful_votes)))
review_texts <- c(review_texts, rep(NA, max_length - length(review_texts)))
# Combine data into a tibble
tibble(
movie_title = rep(movie_title, max_length),  # Add the show title to each review
reviewer_name = reviewer_names,
review_date = date_review,
rating = movie_ratings,
review_title = review_titles,
helpful_votes = helpful_votes,
review_text = review_texts
)
}
# List of IMDb links
links <- c(
"https://www.imdb.com/title/tt0903747/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0795176/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0306414/reviews/?ref_=tt_ov_urv"
)
# Initialize an empty tibble to store all reviews
all_movie_reviews <- tibble()
# Loop through each link and scrape reviews
for (link in links) {
reviews <- rev_scrapes(link)
# Check if reviews are scraped successfully and limit to 20 reviews per link
if (nrow(reviews) > 0) {
reviews <- reviews %>% slice(1:20)  # Limit to the first 20 reviews per link
all_reviews <- bind_rows(all_reviews, reviews)
}
}
# View the first 20 reviews after scraping all links
print(all_reviews)
# Optionally, write the reviews to a CSV file
write.csv(all_movie_reviews, "IMDb_Movie_Reviews.csv", row.names = FALSE)
str(final_data$`Year Released`)
final_data$`Year Released` <- as.numeric(as.character(final_data$`Year Released`))
fdata <- final_data %>% filter(!is.na(`Year Released`))
tv_shows_by_year <- final_data %>%
group_by(`Year Released`) %>%
summarise(num_shows = n()) %>%
arrange(`Year Released`)
# Create a time series plot
ggplot(tv_shows_by_year, aes(x = `Year Released`, y = num_shows)) +
geom_line(color = "blue", size = 1) +
geom_point(color = "red", size = 2) +
labs(title = "Number of TV Shows Released by Year",
x = "Year",
y = "Number of Shows") +
theme_minimal()
polite::use_manners(save_as = 'polite_scrape.R')
url <- 'https://www.amazon.com'
session <- bow(url,
user_agent = "Educational")
session
scrape_amazon_products <- function(base_url, category, num_products = 30) {
all_data <- data.frame()
page_number <- 1
while (nrow(all_data) < num_products) {
# Construct the URL for the current page
url <- paste0(base_url, "&page=", page_number)
message("Scraping: ", url)
page <- read_html(url)
product_titles <- page %>%
html_nodes("span.a-text-normal") %>%
html_text(trim = TRUE)
if (length(product_titles) == 0) product_titles <- NA
price <- page %>%
html_nodes('.a-price .a-offscreen') %>%
html_text(trim = TRUE)
if (length(price) == 0) price <- NA
ratings <- page %>%
html_nodes('span.a-icon-alt') %>%
html_text(trim = TRUE) %>%
str_extract("\\d\\.\\d") %>%
as.numeric()
if (length(ratings) == 0) ratings <- NA
reviews <- page %>%
html_nodes('.s-link-style .s-underline-text') %>%
html_text(trim = TRUE)
if (length(reviews) == 0) reviews <- NA
descriptions <- page %>%
html_nodes("span.a-text-normal") %>%
html_text(trim = TRUE)
if (length(reviews) == 0) reviews <- rep(NA, length(product_titles))
min_length <- min(length(product_titles), length(price), length(ratings), length(descriptions), length(reviews))
if (length(product_titles) > 0 && length(price) > 0 && length(ratings) > 0) {
min_length <- min(length(product_titles), length(price), length(ratings), length(descriptions), length(reviews))
} else {
break
}
# Exit if no products are found on the page
data <- data.frame(
ProductTitle = head(product_titles, min_length),
Price = head(price, min_length),
Category = rep(category, min_length),
Ratings = head(ratings, min_length),
ReviewCount = head(reviews, min_length),
Description = head(descriptions, min_length)
)
all_data <- bind_rows(all_data, data)
page_number <- page_number + 1
}
all_data <- head(all_data, num_products)
all_data$ProductTitle <- paste0(seq_len(nrow(all_data)), ". ", all_data$ProductTitle)
return(all_data)
}
mouseproducts <- scrape_amazon_products(mouse_url, "Mouse", 30)
mouse_url <- "https://www.amazon.com/s?k=mouse&crid=1P0QY16XK63WD&sprefix=mouse%2Caps%2C1195&ref=nb_sb_noss_1"
phone_url <- "https://www.amazon.com/s?k=phone&crid=1WBAK21JA8SUO&sprefix=phone%2Caps%2C2975&ref=nb_sb_noss_2"
boysclothing_url <- "https://www.amazon.com/s?i=specialty-aps&bbn=16225021011&rh=n%3A16225021011%2Cn%3A1040666%2Cp_n_size_six_browse-vebin%3A4940401011&dc&fst=as%3Aoff&pf_rd_i=16225021011&pf_rd_m=ATVPDKIKX0DER&pf_rd_p=d84623b2-8aff-40df-9701-224067aef31e&pf_rd_r=1QWCYMVZ16SKVND2AJS2&pf_rd_s=merchandised-search-3&pf_rd_t=101&qid=1511397964&rnid=49403&ref=s9_acss_bw_cg_AEGFVN2E_1a1_w"
babiesproducts_url <- "https://www.amazon.com/s?i=baby-products-intl-ship&srs=16225005011&rh=n%3A16225005011&s=popularity-rank&fs=true&ref=lp_16225005011_sar"
girlsclothing_url <- "https://www.amazon.com/s?i=specialty-aps&bbn=16225020011&rh=n%3A7141123011%2Cn%3A16225020011%2Cn%3A1040664&ref=nav_em__nav_desktop_sa_intl_clothing_0_2_14_2"
mouseproducts <- scrape_amazon_products(mouse_url, "Mouse", 30)
phoneproducts <- scrape_amazon_products(phone_url, "Phones", 30)
boysclothingproducts <- scrape_amazon_products(boysclothing_url, "Boys' Clothing", 30)
babiessupplyproducts <- scrape_amazon_products(babiesproducts_url, "Babies Supplies", 30)
girlsclothingproducts <- scrape_amazon_products(girlsclothing_url, "Girls' Clothing", 30)
mouseproducts <- scrape_amazon_products(mouse_url, "Mouse", 30)
mouseproducts <- scrape_amazon_products(mouse_url, "Mouse", 30)
mouseproducts <- scrape_amazon_products(mouse_url, "Mouse", 30)
#6. We scraped data for 30 Amazon products from 5 different categories and created a CSV file containing their product titles, prices, descriptions, ratings, and reviews.
#7. The use case for this data would be market research.
#8. The graphs illustrate pricing trends, customer satisfaction, and product popularity, assisting in identifying competitive prices and top-selling products. They also reveal correlations between ratings and reviews, highlighting products that are both highly rated and frequently purchased.
mouseproducts <- scrape_amazon_products(mouse_url, "Mouse", 30)
mouseproducts <- scrape_amazon_products(mouse_url, "Mouse", 30)
mouseproducts <- scrape_amazon_products(mouse_url, "Mouse", 30)
mouseproducts <- scrape_amazon_products(mouse_url, "Mouse", 30)
# Defining a function in order to scrape IMDb reviews
rev_scrapes <- function(url) {
page <- tryCatch(read_html(url), error = function(e) NULL)
if (is.null(page)) {
message("Failed to load page: ", url)
return(tibble())
}
# Scraping the title of the movies
movie_title <- page %>%
html_nodes("h1[data-testid='hero-title-block__title']") %>%
html_text(trim = TRUE)
# Checking if the title was extracted:
if (length(movie_title) == 0) {
message("Failed to extract show title for URL: ", url)
movie_title <- NA  # Set to NA if the title is not found
}
# Extract relevant review data
reviewer_names <- page %>%
html_nodes("a.ipc-link.ipc-link--base") %>%
html_text() %>%
.[. != "Permalink"]
date_review <- page %>%
html_nodes("li.ipc-inline-list__item.review-date") %>%
html_text()
movie_ratings <- page %>%
html_nodes("span.ipc-rating-star--rating") %>%
html_text() %>%
as.numeric()
review_titles <- page %>%
html_nodes("h3.ipc-title__text") %>%
html_text()
helpful_votes <- page %>%
html_nodes("span.ipc-voting__label__count.ipc-voting__label__count--up") %>%
html_text() %>%
as.numeric()
review_texts <- page %>%
html_nodes("div.ipc-html-content-inner-div") %>%
html_text()
# Adjust lengths by padding shorter vectors with NA
max_length <- max(length(reviewer_names), length(date_review), length(movie_ratings), length(review_titles), length(helpful_votes), length(review_texts))
# Pad vectors with NA if they are shorter than max_length
reviewer_names <- c(reviewer_names, rep(NA, max_length - length(reviewer_names)))
date_review <- c(date_review, rep(NA, max_length - length(date_review)))
movie_ratings <- c(movie_ratings, rep(NA, max_length - length(movie_ratings)))
review_titles <- c(review_titles, rep(NA, max_length - length(review_titles)))
helpful_votes <- c(helpful_votes, rep(NA, max_length - length(helpful_votes)))
review_texts <- c(review_texts, rep(NA, max_length - length(review_texts)))
# Combine data into a tibble
tibble(
movie_title = rep(movie_title, max_length),  # Add the show title to each review
reviewer_name = reviewer_names,
review_date = date_review,
rating = movie_ratings,
review_title = review_titles,
helpful_votes = helpful_votes,
review_text = review_texts
)
}
# List of IMDb links
links <- c(
"https://www.imdb.com/title/tt0903747/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0795176/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_ov_urv",
"https://www.imdb.com/title/tt0306414/reviews/?ref_=tt_ov_urv"
)
# Initialize an empty tibble to store all reviews
all_movie_reviews <- tibble()
# Loop through each link and scrape reviews
for (link in links) {
reviews <- rev_scrapes(link)
# Check if reviews are scraped successfully and limit to 20 reviews per link
if (nrow(reviews) > 0) {
reviews <- reviews %>% slice(1:20)  # Limit to the first 20 reviews per link
all_movie_reviews <- bind_rows(all_movie_reviews, reviews)
}
}
# View the first 20 reviews after scraping all links
print(all_movie_reviews)
# Optionally, write the reviews to a CSV file
write.csv(all_movie_reviews, "IMDb_Movie_Reviews.csv", row.names = FALSE)
