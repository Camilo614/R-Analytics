---
title: "RWorksheet#5_group(Leysa,Calambro)"
author: "Camilo Leysa"
date: "2024-11-11"
output: pdf_document
---


Loading needed libraries:
```{r}
library(rvest)
library(polite)
library(dplyr)
library(httr)
library(stringr)
library(ggplot2)
library(tibble)
```

```{r}
polite::use_manners(save_as = "polite_scrape_tvshows.R")
url <- "https://www.imdb.com/chart/toptv/?ref_=nv_tvv_250" 
session <- bow(url, user_agent = "Educational")
session
```

1. 

Getting the TV Show title.
```{r}
#Title
title_lists <- scrape(session) %>% html_nodes("h3.ipc-title__text") %>% html_text(trim = TRUE)
#filter unwanted
title_lists <- title_lists[!grepl("Recently viewed", title_lists)]
title_lists
```

List of top 50 TV Shows
```{r}
class(title_lists)
title_List <- as.data.frame(title_lists[2:51])
title_List
```

Seperating the rank number and the TV Show title.
```{r}
colnames(title_List) <- "ranks"
split_df <- strsplit(as.character(title_List$ranks),".",fixed = TRUE)
split_df <- data.frame(do.call(rbind,split_df))
split_df <- split_df[-c(3:4)] 
colnames(split_df) <- c("Ranks","Title") 
str(split_df)
```

The Rank and the Title of the TV Shows
```{r}
class(split_df)
split_df
```

Top 50 TV Show Rating
```{r}
rating <- scrape(session) %>% html_nodes("span.ipc-rating-star--rating") %>% html_text
tv_rating <- as.data.frame(rating [1:50])
tv_rating
```
Number of People who Voted
```{r}
tv_votes <- scrape(session) %>% html_nodes("span.ipc-rating-star--voteCount") %>% html_text
total_tv_votes <- as.data.frame(tv_votes[1:50])
total_tv_votes
```
Number of Episodes of each TV Shows
```{r}
episodes <- scrape(session) %>% html_nodes("span.sc-300a8231-7.eaXxft.cli-title-metadata-item") %>% html_text
cl_episodes <- gsub("\\D", "", episodes)
cleaned_ep <- str_extract(episodes, "\\d+(?=\\s*eps)")
cleaned_ep <- as.numeric(cleaned_ep)
cleaned_ep <- cleaned_ep[!is.na(cleaned_ep)]
cleaned_episodes <- as.data.frame(cleaned_ep[1:25])
cleaned_episodes
```
Year of TV Shows released
```{r}
tv_years <- scrape(session) %>% html_nodes("span.sc-300a8231-7.eaXxft.cli-title-metadata-item") %>% html_text
clyear <- gsub(".*?(\\d{4}(-\\d{4})?).*", "\\1", tv_years)
yeartv <- str_extract(tv_years, "\\b\\d{4}(-\\d{4})?\\b")
yeartv <- as.numeric(yeartv)
yeartv <- yeartv[!is.na(yeartv)]
tv_year_of_air <- as.data.frame(yeartv[1:50])
tv_year_of_air
```

Number of User Reviews
```{r}
review <- scrape(session) %>% html_nodes("ul.ipc-inline-list.sc-b782214c-0.bllRjU.baseAlt") %>% html_text
reviews <- as.data.frame(review[1:50])
reviews
#tried several links but still getting NA's.
```
Getting the number of Critic Reviews
```{r}
critic <- scrape(session) %>% html_nodes("ul.ipc-inline-list.sc-b782214c-0.bllRjU.baseAlt") %>% html_text
critic_rev <- as.data.frame(critic [1:50])
critic_rev
#tried several links but still getting NA's.
```

Getting the popularity Review
```{r}
popularity_review <- scrape(session) %>% html_nodes("div.hero-rating-bar__popularity__down") %>% html_text
pop <- as.data.frame(popularity_review [1:50])
pop
#tried several links but still getting NA's.
```





Data frame of TV Shows
```{r}
final_data <- cbind(split_df,tv_rating,total_tv_votes,cleaned_episodes,tv_year_of_air,reviews,critic_rev,pop)
colnames(final_data) <- c("Ranks", "TV Show Title", "Rating", "Number of People Voted", "Number of Episodes", "Year Released", "User Reviews", "Critic Reviews", "Popularity Review")
final_data
write.csv(final_data, "Top_50_tvshows.csv", row.names = FALSE)
```

2. 

```{r}
# Defining a function in order to scrape IMDb reviews
rev_scrapes <- function(url) {
  page <- tryCatch(read_html(url), error = function(e) NULL)
  if (is.null(page)) {
    message("Failed to load page: ", url)
    return(tibble())
  }
  
  # Scraping the title of the movies 
  movie_title <- page %>%
    html_nodes("h1[data-testid='hero-title-block__title']") %>%
    html_text(trim = TRUE)
  
  # Checking if the title was extracted:
  if (length(movie_title) == 0) {
    message("Failed to extract show title for URL: ", url)
    movie_title <- NA  # Set to NA if the title is not found
  }
  
  # Extract relevant review data
  reviewer_names <- page %>% 
    html_nodes("a.ipc-link.ipc-link--base") %>% 
    html_text() %>% 
    .[. != "Permalink"]
  
  date_review <- page %>% 
    html_nodes("li.ipc-inline-list__item.review-date") %>% 
    html_text()
  
  movie_ratings <- page %>% 
    html_nodes("span.ipc-rating-star--rating") %>% 
    html_text() %>% 
    as.numeric()
  
  review_titles <- page %>% 
    html_nodes("h3.ipc-title__text") %>% 
    html_text()
  
  helpful_votes <- page %>% 
    html_nodes("span.ipc-voting__label__count.ipc-voting__label__count--up") %>% 
    html_text() %>% 
    as.numeric()
  
  review_texts <- page %>% 
    html_nodes("div.ipc-html-content-inner-div") %>% 
    html_text()
  
  # Adjust lengths by padding shorter vectors with NA
  max_length <- max(length(reviewer_names), length(date_review), length(movie_ratings), length(review_titles), length(helpful_votes), length(review_texts))
  
  # Pad vectors with NA if they are shorter than max_length
  reviewer_names <- c(reviewer_names, rep(NA, max_length - length(reviewer_names)))
  date_review <- c(date_review, rep(NA, max_length - length(date_review)))
  movie_ratings <- c(movie_ratings, rep(NA, max_length - length(movie_ratings)))
  review_titles <- c(review_titles, rep(NA, max_length - length(review_titles)))
  helpful_votes <- c(helpful_votes, rep(NA, max_length - length(helpful_votes)))
  review_texts <- c(review_texts, rep(NA, max_length - length(review_texts)))
  
  # Combine data into a tibble
  tibble(
    movie_title = rep(movie_title, max_length),  # Add the show title to each review
    reviewer_name = reviewer_names,
    review_date = date_review,
    rating = movie_ratings,
    review_title = review_titles,
    helpful_votes = helpful_votes,
    review_text = review_texts
  )
}

# List of IMDb links
links <- c(
  "https://www.imdb.com/title/tt0903747/reviews/?ref_=tt_ov_urv",
  "https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_ov_urv",
  "https://www.imdb.com/title/tt0795176/reviews/?ref_=tt_ov_urv",
  "https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_ov_urv",
  "https://www.imdb.com/title/tt0306414/reviews/?ref_=tt_ov_urv"
)

# Initialize an empty tibble to store all reviews
all_movie_reviews <- tibble()

# Loop through each link and scrape reviews
for (link in links) {
  reviews <- rev_scrapes(link)
  
  # Check if reviews are scraped successfully and limit to 20 reviews per link
  if (nrow(reviews) > 0) {
    reviews <- reviews %>% slice(1:20)  # Limit to the first 20 reviews per link
    all_movie_reviews <- bind_rows(all_movie_reviews, reviews)
  }
}

# View the first 20 reviews after scraping all links
print(all_movie_reviews)

# Optionally, write the reviews to a CSV file
write.csv(all_movie_reviews, "IMDb_Movie_Reviews.csv", row.names = FALSE)
```



3. Graph of each TV show releases each year
```{r}
str(final_data$`Year Released`)
final_data$`Year Released` <- as.numeric(as.character(final_data$`Year Released`))
fdata <- final_data %>% filter(!is.na(`Year Released`))
tv_shows_by_year <- final_data %>%
  group_by(`Year Released`) %>%
  summarise(num_shows = n()) %>%
  arrange(`Year Released`)

# Create a time series plot
ggplot(tv_shows_by_year, aes(x = `Year Released`, y = num_shows)) +
  geom_line(color = "blue", size = 1) +
  geom_point(color = "red", size = 2) +
  labs(title = "Number of TV Shows Released by Year",
       x = "Year",
       y = "Number of Shows") +
  theme_minimal()
```









AMAZON PART

```{r}
polite::use_manners(save_as = 'polite_scrape.R')

url <- 'https://www.amazon.com'


session <- bow(url,
               user_agent = "Educational")
session
```

```{r}
scrape_amazon_products <- function(base_url, category, num_products = 30) {
  all_data <- data.frame()
  page_number <- 1
  
  while (nrow(all_data) < num_products) {
    # Construct the URL for the current page
    url <- paste0(base_url, "&page=", page_number)
    message("Scraping: ", url)
    
    page <- read_html(url)
    
    product_titles <- page %>%
      html_nodes("span.a-text-normal") %>% 
      html_text(trim = TRUE)
    if (length(product_titles) == 0) product_titles <- NA
    
   
    price <- page %>% 
      html_nodes('.a-price .a-offscreen') %>% 
      html_text(trim = TRUE)
     if (length(price) == 0) price <- NA
    
    ratings <- page %>% 
      html_nodes('span.a-icon-alt') %>% 
      html_text(trim = TRUE) %>%
      str_extract("\\d\\.\\d") %>%  
      as.numeric()
    if (length(ratings) == 0) ratings <- NA


    reviews <- page %>%
      html_nodes('.s-link-style .s-underline-text') %>% 
      html_text(trim = TRUE)
    if (length(reviews) == 0) reviews <- NA
    
    descriptions <- page %>%
      html_nodes("span.a-text-normal") %>% 
      html_text(trim = TRUE)
    if (length(reviews) == 0) reviews <- rep(NA, length(product_titles))
    
    
    min_length <- min(length(product_titles), length(price), length(ratings), length(descriptions), length(reviews))
     if (length(product_titles) > 0 && length(price) > 0 && length(ratings) > 0) {
  min_length <- min(length(product_titles), length(price), length(ratings), length(descriptions), length(reviews))
} else {
  break
}
  # Exit if no products are found on the page
    
    data <- data.frame(
      ProductTitle = head(product_titles, min_length),
      Price = head(price, min_length),
      Category = rep(category, min_length),
      Ratings = head(ratings, min_length),
      ReviewCount = head(reviews, min_length),
      Description = head(descriptions, min_length)
    )
    
    
    all_data <- bind_rows(all_data, data)
    
    page_number <- page_number + 1
     

  }
  all_data <- head(all_data, num_products)
  

  all_data$ProductTitle <- paste0(seq_len(nrow(all_data)), ". ", all_data$ProductTitle)
  
  return(all_data)
}
 
```


```{r}
mouse_url <- "https://www.amazon.com/s?k=mouse&crid=1P0QY16XK63WD&sprefix=mouse%2Caps%2C1195&ref=nb_sb_noss_1"
phone_url <- "https://www.amazon.com/s?k=phone&crid=1WBAK21JA8SUO&sprefix=phone%2Caps%2C2975&ref=nb_sb_noss_2"
boysclothing_url <- "https://www.amazon.com/s?i=specialty-aps&bbn=16225021011&rh=n%3A16225021011%2Cn%3A1040666%2Cp_n_size_six_browse-vebin%3A4940401011&dc&fst=as%3Aoff&pf_rd_i=16225021011&pf_rd_m=ATVPDKIKX0DER&pf_rd_p=d84623b2-8aff-40df-9701-224067aef31e&pf_rd_r=1QWCYMVZ16SKVND2AJS2&pf_rd_s=merchandised-search-3&pf_rd_t=101&qid=1511397964&rnid=49403&ref=s9_acss_bw_cg_AEGFVN2E_1a1_w"
babiesproducts_url <- "https://www.amazon.com/s?i=baby-products-intl-ship&srs=16225005011&rh=n%3A16225005011&s=popularity-rank&fs=true&ref=lp_16225005011_sar"
girlsclothing_url <- "https://www.amazon.com/s?i=specialty-aps&bbn=16225020011&rh=n%3A7141123011%2Cn%3A16225020011%2Cn%3A1040664&ref=nav_em__nav_desktop_sa_intl_clothing_0_2_14_2"
```



```{r}
mouseproducts <- scrape_amazon_products(mouse_url, "Mouse", 30)
phoneproducts <- scrape_amazon_products(phone_url, "Phones", 30)
boysclothingproducts <- scrape_amazon_products(boysclothing_url, "Boys' Clothing", 30)
babiessupplyproducts <- scrape_amazon_products(babiesproducts_url, "Babies Supplies", 30)
girlsclothingproducts <- scrape_amazon_products(girlsclothing_url, "Girls' Clothing", 30)

all_products <- bind_rows(mouseproducts, phoneproducts, boysclothingproducts, babiessupplyproducts, girlsclothingproducts)

print(all_products)

write.csv(all_products, "Amazon_products.csv")
```

```{r}
#6. We scraped data for 30 Amazon products from 5 different categories and created a CSV file containing their product titles, prices, descriptions, ratings, and reviews.

#7. The use case for this data would be market research.

#8. The graphs illustrate pricing trends, customer satisfaction, and product popularity, assisting in identifying competitive prices and top-selling products. They also reveal correlations between ratings and reviews, highlighting products that are both highly rated and frequently purchased.
```

```{r}
# Load the CSV file containing the products
all_products <- read.csv("Amazon_products.csv")

# Ensure the Ratings column is numeric for sorting
all_products$Ratings <- as.numeric(all_products$Ratings)

# Check the structure to make sure Ratings are correctly formatted
str(all_products)

# Rank products by Ratings in descending order
ranked_by_ratings <- all_products %>%
  arrange(desc(Ratings))

# View the top-ranked products based on ratings
head(ranked_by_ratings, 150)  # Display the top 10 highest-rated products
```

```{r}
# Load the CSV file containing the products
all_products <- read.csv("Amazon_products.csv")

# Clean and convert the Price column to numeric (if it includes "$" signs)
all_products$Price <- as.numeric(gsub("\\$", "", all_products$Price))

# Check the structure to ensure Price is correctly formatted
str(all_products)

# Rank products by Price in ascending order (cheapest first)
ranked_by_price_ascending <- all_products %>%
  arrange(Price)

# Alternatively, rank products by Price in descending order (most expensive first)
ranked_by_price_descending <- all_products %>%
  arrange(desc(Price))

# View the top-ranked products based on price (descending order)
head(ranked_by_price_descending, 150)  # Display top 10 most expensive products
```



















